sub_avx_64_aligned.c:436:17: optimized: basic block part vectorized using 64 byte vectors
sub_avx_64_aligned.c:706:19: optimized: basic block part vectorized using 64 byte vectors
sub_avx_64_aligned.c:728:17: optimized: basic block part vectorized using 64 byte vectors
sub_avx_64_aligned.c:823:27: optimized: loop vectorized using 64 byte vectors
sub_avx_64_aligned.c:823:27: optimized:  loop versioned for vectorization because of possible aliasing
sub_avx_64_aligned.c:823:27: optimized: loop vectorized using 32 byte vectors
sub_avx_64_aligned.c:861:23: optimized: loop vectorized using 32 byte vectors
sub_avx_64_aligned.c:861:23: optimized: loop vectorized using 16 byte vectors
sub_avx_64_aligned.c:861:23: optimized: loop vectorized using 32 byte vectors
sub_avx_64_aligned.c:861:23: optimized:  loop versioned for vectorization because of possible aliasing
sub_avx_64_aligned.c:861:23: optimized: loop vectorized using 16 byte vectors
sub_avx_64_aligned.c:861:23: optimized: loop vectorized using 32 byte vectors
sub_avx_64_aligned.c:861:23: optimized:  loop versioned for vectorization because of possible aliasing
sub_avx_64_aligned.c:861:23: optimized: loop vectorized using 16 byte vectors
