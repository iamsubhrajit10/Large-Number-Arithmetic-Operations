movq	%r8, %rsi
	shrdq	$52, %rdi, %rsi
	addq	%rsi, 184(%r10)
	movq	16(%rcx), %r9
	movabsq	$4503599627370495, %rsi
	andq	%rsi, %r8
	addq	%r9, (%r10)
	movq	40(%rcx), %r11
	addq	%r11, 16(%r10)
	movq	72(%rcx), %rdx
	addq	%rdx, 40(%r10)
	movq	112(%rcx), %rdi
	addq	%rdi, 72(%r10)
	movq	%r8, 72(%rcx)
	movq	184(%r10), %r8
	addq	176(%r10), %r8
	movq	%r8, %rax
	shrq	$52, %r8
	andq	%rsi, %rax
	movq	%rax, 64(%rcx)
	movq	160(%r10), %r9
	addq	152(%r10), %r9
	addq	168(%r10), %r9
	addq	%r8, %r9
	movq	%r9, %r11
	shrq	$52, %r9
	andq	%rsi, %r11
	movq	%r11, 56(%rcx)
	movq	128(%r10), %rdx
	addq	120(%r10), %rdx
	addq	136(%r10), %rdx
	addq	144(%r10), %rdx
	addq	%r9, %rdx
	movq	%rdx, %rdi
	shrq	$52, %rdx
	andq	%rsi, %rdi
	movq	%rdi, 48(%rcx)
	movq	88(%r10), %r8
	addq	80(%r10), %r8
	addq	96(%r10), %r8
	addq	104(%r10), %r8
	addq	112(%r10), %r8
	addq	%rdx, %r8
	movq	%r8, %rax
	shrq	$52, %r8
	andq	%rsi, %rax
	movq	%rax, 40(%rcx)
	movq	56(%r10), %r9
	addq	48(%r10), %r9
	addq	64(%r10), %r9
	addq	72(%r10), %r9
	addq	%r9, %r8
	movq	%r8, %r11
	andq	%rsi, %r11
	shrq	$52, %r8
	movq	%r11, 32(%rcx)
	movq	32(%r10), %rdx
	addq	24(%r10), %rdx
	addq	40(%r10), %rdx
	addq	%r8, %rdx
	movq	%rdx, %rdi
	shrq	$52, %rdx
	andq	%rsi, %rdi
	movq	%rdi, 24(%rcx)
	movq	16(%r10), %r8
	addq	8(%r10), %r8
	addq	%rdx, %r8
	movq	%r8, %rax
	shrq	$52, %r8
	andq	%rsi, %rax
	movq	%rax, 16(%rcx)
	addq	(%r10), %r8
	andq	%r8, %rsi
	shrq	$52, %r8
	addq	%r8, (%rcx)
	movq	%rsi, 8(%rcx)
	vzeroupper
	ret
	.cfi_endproc